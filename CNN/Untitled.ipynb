{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f236f5d-ef0d-4554-b7db-61fff6fe5e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2411ad38-2bc5-45ef-a3e9-3c0bf5fd6442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "785c5ad0-69bf-46b5-a002-ec7ff19acb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense , Conv2D , MaxPooling2D , Flatten\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b51628-c9f4-4dbb-a8cb-cce5a6678d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn= Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da0bba62-e1b3-45ca-bc13-3b724402e948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "cnn.add(Conv2D(32,(3,3), input_shape = (128,128,3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size= (2,2)))\n",
    "cnn.add(Conv2D(16,(3,3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size= (2,2)))\n",
    "cnn.add(Flatten())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c632f4e-9d98-4226-ba48-4efb16976ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(64 ,activation='relu'))\n",
    "cnn.add(Dense(32 ,activation='relu'))\n",
    "cnn.add(Dense(16 ,activation='relu'))\n",
    "cnn.add(Dense(8 ,activation='relu'))\n",
    "cnn.add(Dense(4 ,activation='relu'))\n",
    "cnn.add(Dense(1 ,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61d97efc-e640-47da-8a0c-1b8b41870c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss='binary_crossentropy' , optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcda5245-c4af-40e5-b4e4-05c7f84a5735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11500 images belonging to 2 classes.\n",
      "Found 2119 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 379ms/step - loss: 0.6938 - val_loss: 0.6930\n",
      "Epoch 2/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 358ms/step - loss: 0.6931 - val_loss: 0.6929\n",
      "Epoch 3/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 345ms/step - loss: 0.6934 - val_loss: 0.6930\n",
      "Epoch 4/10\n",
      "\u001b[1m 60/100\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 276ms/step - loss: 0.6932"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 223ms/step - loss: 0.6932 - val_loss: 0.6930\n",
      "Epoch 5/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 357ms/step - loss: 0.6932 - val_loss: 0.6931\n",
      "Epoch 6/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 348ms/step - loss: 0.6932 - val_loss: 0.6930\n",
      "Epoch 7/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 331ms/step - loss: 0.6932 - val_loss: 0.6933\n",
      "Epoch 8/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 278ms/step - loss: 0.6931 - val_loss: 0.6933\n",
      "Epoch 9/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 359ms/step - loss: 0.6932 - val_loss: 0.6931\n",
      "Epoch 10/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 364ms/step - loss: 0.6932 - val_loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x213c73e5c40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r'D:\\Deep Learning\\CNN\\train_data',\n",
    "        target_size=(128,128),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        r'D:\\Deep Learning\\CNN\\test_data',\n",
    "        target_size=(128,128),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "cnn.fit(train_generator,steps_per_epoch=100,epochs=10,validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d2fddd1-9997-407e-9927-69797f53dc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862b86a3-f3a3-480f-aa5f-371f043b2ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d14f393-752a-4558-90ef-fbe837be06c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "img1 = image.load_img(r'D:\\Deep Learning\\CNN\\Predict\\cattt.jpeg', target_size=(128,128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "144e7939-2a43-4637-9fbe-6155e4c4d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = image.load_img(r'D:\\Deep Learning\\CNN\\Predict\\dog.jpeg', target_size=(128,128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6f456cc-ee5c-4156-ac82-62be0c49c7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1=image.img_to_array(img1)\n",
    "img2=image.img_to_array(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "645a9e3f-15fc-481e-bee7-8e3d2bf1ecbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[214., 211., 180.],\n",
       "        [220., 216., 189.],\n",
       "        [230., 225., 203.],\n",
       "        ...,\n",
       "        [234., 226., 213.],\n",
       "        [230., 227., 212.],\n",
       "        [229., 226., 211.]],\n",
       "\n",
       "       [[213., 210., 179.],\n",
       "        [219., 215., 188.],\n",
       "        [230., 225., 203.],\n",
       "        ...,\n",
       "        [228., 225., 210.],\n",
       "        [229., 226., 211.],\n",
       "        [234., 218., 205.]],\n",
       "\n",
       "       [[212., 209., 178.],\n",
       "        [218., 214., 187.],\n",
       "        [229., 224., 202.],\n",
       "        ...,\n",
       "        [231., 222., 207.],\n",
       "        [232., 218., 205.],\n",
       "        [236., 203., 194.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[176., 144., 106.],\n",
       "        [178., 146., 108.],\n",
       "        [180., 148., 110.],\n",
       "        ...,\n",
       "        [209., 196., 180.],\n",
       "        [213., 200., 184.],\n",
       "        [212., 199., 183.]],\n",
       "\n",
       "       [[191., 158., 125.],\n",
       "        [189., 156., 123.],\n",
       "        [189., 156., 123.],\n",
       "        ...,\n",
       "        [213., 200., 184.],\n",
       "        [220., 207., 191.],\n",
       "        [219., 206., 190.]],\n",
       "\n",
       "       [[194., 161., 130.],\n",
       "        [189., 156., 125.],\n",
       "        [188., 155., 124.],\n",
       "        ...,\n",
       "        [214., 201., 185.],\n",
       "        [224., 211., 195.],\n",
       "        [227., 214., 198.]]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "450c66fb-dccd-4411-99dc-2e9b0014d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55ca1aa4-a53b-431e-a497-6d272a0638c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1= np.expand_dims(img1 , axis=0)\n",
    "img2= np.expand_dims(img2 , axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "233ef5c0-8303-4355-8074-da58ce56d70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n"
     ]
    }
   ],
   "source": [
    "p1=cnn.predict(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "215eb9b4-48ec-49ed-859c-e54eb24ebc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n"
     ]
    }
   ],
   "source": [
    "p2=cnn.predict(img2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f36ebda7-e595-4763-987c-ff77d1d39bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog\n"
     ]
    }
   ],
   "source": [
    "if p1[0][0]<0.5:\n",
    "    print('Dog')\n",
    "else:\n",
    "    print('Cat')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "607c56ad-6889-4626-8165-0c27eae62251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog\n"
     ]
    }
   ],
   "source": [
    "if p2[0][0]<0.5:\n",
    "    print('Dog')\n",
    "else:\n",
    "    print('Cat')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059edeeb-c3f6-4832-86ae-648857d09c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b8159-2ae0-400e-9232-5c77a790aa6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f93b239-8a84-4f09-a2ca-4a568fb0d300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
