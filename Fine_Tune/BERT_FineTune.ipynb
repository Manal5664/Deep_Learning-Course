{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3299c9f2ce8445ca9e6073dab7c42df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5daa8bf798f143fe9be7a7651faf95ae",
              "IPY_MODEL_b24b3432e9d34d3ca8c6b815ddb8b587",
              "IPY_MODEL_f8c70bb1376c410db9b9eb6c30d0c392"
            ],
            "layout": "IPY_MODEL_d94b14f04a19429d84ac730d6c23198b"
          }
        },
        "5daa8bf798f143fe9be7a7651faf95ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30840515b92545a9a48d7bb16e1a5a1d",
            "placeholder": "​",
            "style": "IPY_MODEL_130531e18a4046b89e8626ef9feac433",
            "value": "model.safetensors: 100%"
          }
        },
        "b24b3432e9d34d3ca8c6b815ddb8b587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a39553be7dd40859e7554f60a67b852",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f1984d9ee4e42a792b6d624fe43e382",
            "value": 440449768
          }
        },
        "f8c70bb1376c410db9b9eb6c30d0c392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6db6f7c5c9742eb81ed9f8fd7f50cde",
            "placeholder": "​",
            "style": "IPY_MODEL_cf762abb47ed4ad5a610aed51bf504db",
            "value": " 440M/440M [00:05&lt;00:00, 149MB/s]"
          }
        },
        "d94b14f04a19429d84ac730d6c23198b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30840515b92545a9a48d7bb16e1a5a1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "130531e18a4046b89e8626ef9feac433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a39553be7dd40859e7554f60a67b852": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f1984d9ee4e42a792b6d624fe43e382": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6db6f7c5c9742eb81ed9f8fd7f50cde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf762abb47ed4ad5a610aed51bf504db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Dependencies\n",
        "\n",
        "## 1. transformers\n",
        "\n",
        "### What it is:\n",
        "A library by HuggingFace containing pretrained models like BERT, RoBERTa, GPT, DistilBERT, T5, etc.\n",
        "\n",
        "Why we install it:\n",
        "To use:\n",
        "- BERT tokenizer\n",
        "- BERT for classification\n",
        "- Sequence models (NER, QA, Summarization)\n",
        "- Trainer API\n",
        "\n",
        "In simple words:\n",
        "- Gives you ready-made AI models like BERT and GPT.\n",
        "\n",
        "## 2. datasets\n",
        "\n",
        "### What it is:\n",
        "A HuggingFace library for handling datasets efficiently.\n",
        "\n",
        "Why we install it:\n",
        "- Load datasets very fast\n",
        "- Tokenize large datasets with multiprocessing\n",
        "- Works directly with Trainer API\n",
        "\n",
        "In simple words:\n",
        "- Helps load and process large datasets easily and fast.\n",
        "\n",
        "## 3. torch (PyTorch)\n",
        "\n",
        "### What it is:\n",
        "The deep learning framework used to train neural networks.\n",
        "\n",
        "Why we install it:\n",
        "- Transformers library uses PyTorch backend\n",
        "- Needed for training BERT, DistilBERT, etc.\n",
        "- Provides tensors, GPU acceleration, neural network layers\n",
        "\n",
        "In simple words:\n",
        "- This is the engine that trains the BERT model.\n",
        "\n",
        "## 4. scikit-learn\n",
        "\n",
        "### What it is:\n",
        "A machine-learning library.\n",
        "\n",
        "Why we install it:\n",
        "- Train/test split\n",
        "- Accuracy score\n",
        "- Classification report\n",
        "- Traditional ML models (SVM, RF, etc.)\n",
        "\n",
        "In simple words:\n",
        "- Used to measure accuracy and prepare data.\n",
        "\n",
        "## 5. pandas\n",
        "\n",
        "### What it is:\n",
        "A data handling and manipulation library.\n",
        "\n",
        "Why we install it:\n",
        "- To read CSV datasets\n",
        "- Create DataFrames\n",
        "- Clean and preprocess text data\n",
        "\n",
        "In simple words:\n",
        "- Used to load and handle your dataset.\n",
        "\n",
        "## 6. --quiet\n",
        "\n",
        "### What it is:\n",
        "A flag that hides installation logs.\n",
        "\n",
        "Why we use it:\n",
        "- To keep notebook output clean\n",
        "- Prevent long installation messages\n",
        "\n",
        "In simple words:\n",
        "- Installs everything silently without showing long messages."
      ],
      "metadata": {
        "id": "-BXiQIXlnTMa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YfIkSmpgnI-f"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets torch scikit-learn pandas --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries\n",
        "\n",
        "## 1. import pandas as pd\n",
        "\n",
        "**What it does:**\n",
        "Loads the **pandas** library and gives it the short name `pd`.\n",
        "\n",
        "**Why we use it:**\n",
        "\n",
        "* Read CSV files\n",
        "* Create & manipulate DataFrames\n",
        "* Handle text datasets\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "```\n",
        "\n",
        "## 2. import numpy as np\n",
        "\n",
        "**What it does:**\n",
        "Loads **NumPy**, a numerical computing library.\n",
        "\n",
        "**Why we use it:**\n",
        "\n",
        "* Handle arrays\n",
        "* Perform numerical operations\n",
        "* Convert data to `numpy` format\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "arr = np.array([1,2,3])\n",
        "```\n",
        "\n",
        "## 3. import torch\n",
        "\n",
        "**What it does:**\n",
        "Loads **PyTorch**, the deep learning framework.\n",
        "\n",
        "**Why we use it:**\n",
        "\n",
        "* Create tensors\n",
        "* Move data to GPU\n",
        "* Build & train neural networks\n",
        "* Used internally by Transformers\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "x = torch.tensor([1, 2, 3])\n",
        "```\n",
        "\n",
        "## 4. from sklearn.model_selection import train_test_split\n",
        "\n",
        "**What it does:**\n",
        "Imports the function that **splits dataset** into:\n",
        "\n",
        "* Training set\n",
        "* Validation set\n",
        "* Test set\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "train_df, val_df = train_test_split(df, test_size=0.2)\n",
        "```\n",
        "\n",
        "## 5. from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "**What these do:**\n",
        "\n",
        "### accuracy_score\n",
        "\n",
        "* Measures how many predictions were correct.\n",
        "* Used for classification tasks.\n",
        "\n",
        "### classification_report\n",
        "\n",
        "* Prints precision, recall, F1-score.\n",
        "* Gives detailed model evaluation.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "print(accuracy_score(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred))\n",
        "```\n",
        "\n",
        "## 6. BertTokenizer\n",
        "\n",
        "**What it does:**\n",
        "Converts text → tokens → model input format.\n",
        "\n",
        "**Why needed:**\n",
        "BERT cannot read raw text.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "tokens = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "```\n",
        "\n",
        "## 7. BertForSequenceClassification\n",
        "\n",
        "**What it does:**\n",
        "A pretrained BERT model **for classification tasks**, such as:\n",
        "\n",
        "* Sentiment analysis\n",
        "* Spam detection\n",
        "* Fake review detection\n",
        "* Topic classification\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "```\n",
        "\n",
        "## 8. BertForTokenClassification\n",
        "\n",
        "**What it does:**\n",
        "Model used for **NER (Named Entity Recognition)**:\n",
        "\n",
        "* PERSON\n",
        "* LOCATION\n",
        "* ORGANIZATION\n",
        "* Dates\n",
        "* Medical terms\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\")\n",
        "```\n",
        "\n",
        "## 9. BertTokenizerFast\n",
        "\n",
        "**What it does:**\n",
        "A **faster** tokenizer than `BertTokenizer`.\n",
        "Uses Rust backend for speed.\n",
        "\n",
        "**Why use it:**\n",
        "\n",
        "* Faster NER tokenization\n",
        "* Keeps word_ids (needed for token classification)\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "```\n",
        "\n",
        "## 10. BertModel\n",
        "\n",
        "**What it does:**\n",
        "Loads **BERT without any classification head**.\n",
        "\n",
        "Used when you only want embeddings for:\n",
        "\n",
        "* Sentence similarity\n",
        "* Feature extraction\n",
        "* Custom models\n",
        "* Clustering / semantic search\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "```\n",
        "\n",
        "## 11. AutoTokenizer\n",
        "\n",
        "**What it does:**\n",
        "Automatically loads the right tokenizer for **any model**.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "```\n",
        "\n",
        "## 12. AutoModelForSequenceClassification\n",
        "\n",
        "**What it does:**\n",
        "Loads the correct model for classification **automatically**, e.g.:\n",
        "\n",
        "* BERT\n",
        "* DistilBERT\n",
        "* ALBERT\n",
        "* RoBERTa\n",
        "* MobileBERT\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "```\n",
        "\n",
        "## 13. Trainer\n",
        "\n",
        "**What it does:**\n",
        "Handles the entire training loop automatically:\n",
        "\n",
        "* Training\n",
        "* Evaluation\n",
        "* Saving checkpoints\n",
        "* Logging\n",
        "* Batching\n",
        "* GPU usage\n",
        "\n",
        "**You don’t write manual loops.**\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "trainer = Trainer(model=model, args=training_args, train_dataset=train_data)\n",
        "```\n",
        "\n",
        "\n",
        "## 14. TrainingArguments\n",
        "\n",
        "**What it does:**\n",
        "Configures HOW training happens:\n",
        "\n",
        "* learning rate\n",
        "* batch size\n",
        "* number of epochs\n",
        "* where to save model\n",
        "* evaluation strategy\n",
        "* logging\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "3vyWQKkJohXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from transformers import (\n",
        "    BertTokenizer, BertForSequenceClassification,\n",
        "    BertForTokenClassification, BertForSequenceClassification,\n",
        "    BertTokenizerFast, BertModel,\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    Trainer, TrainingArguments\n",
        ")"
      ],
      "metadata": {
        "id": "_1rQyWwinenf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3a73171-09eb-474f-e97e-95f5b2ece908"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 01: Binary Classification"
      ],
      "metadata": {
        "id": "1DqGzawPp_zf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "E-Zo6CbLqL7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"text\": [\n",
        "        \"I love this phone!\", \"This is terrible.\",\n",
        "        \"Amazing performance!\", \"Worst battery ever.\",\n",
        "        \"I am very happy.\", \"I hate this.\",\n",
        "        \"I lost my friend\"\n",
        "    ],\n",
        "    \"label\": [1,0,1,0,1,0,0]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGTEvxGvocPC",
        "outputId": "e5e67cd2-fb01-44cd-a5d4-39f49db47b32"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   text  label\n",
            "0    I love this phone!      1\n",
            "1     This is terrible.      0\n",
            "2  Amazing performance!      1\n",
            "3   Worst battery ever.      0\n",
            "4      I am very happy.      1\n",
            "5          I hate this.      0\n",
            "6      I lost my friend      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split"
      ],
      "metadata": {
        "id": "8-5PDOI_qOis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "print(train_df)\n",
        "print(val_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLL94Lz2qFV9",
        "outputId": "e021b662-e7aa-4796-8d47-f7d9b7d42faf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   text  label\n",
            "5          I hate this.      0\n",
            "2  Amazing performance!      1\n",
            "4      I am very happy.      1\n",
            "3   Worst battery ever.      0\n",
            "6      I lost my friend      0\n",
            "                 text  label\n",
            "0  I love this phone!      1\n",
            "1   This is terrible.      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer + Dataset Class\n",
        "\n",
        "### 1. Load the BERT Tokenizer\n",
        "\n",
        "```python\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "```\n",
        "\n",
        "#### What this line does:\n",
        "\n",
        "* Downloads the **BERT tokenizer**.\n",
        "* \"bert-base-uncased\" = lowercase English model.\n",
        "* Tokenizer converts text → tokens → input IDs → attention masks.\n",
        "\n",
        "### 2. Start of Custom Dataset Class\n",
        "\n",
        "```python\n",
        "class BERTDataset(torch.utils.data.Dataset):\n",
        "```\n",
        "\n",
        "#### What this line does:\n",
        "\n",
        "* Creates a **custom PyTorch dataset**.\n",
        "* This Dataset will later be used by DataLoader and Trainer.\n",
        "* It tells PyTorch how to feed BERT with data.\n",
        "\n",
        "### 3. Constructor Method\n",
        "\n",
        "```python\n",
        "def __init__(self, text, labels, tokenizer, max_len=64):\n",
        "```\n",
        "\n",
        "#### What this does:\n",
        "\n",
        "This function is called when you create the dataset.\n",
        "\n",
        "It receives:\n",
        "\n",
        "* `text` → list of sentences\n",
        "* `labels` → list of labels (0/1, or multi-class)\n",
        "* `tokenizer` → BERT tokenizer\n",
        "* `max_len` → maximum token length (default 64 tokens)\n",
        "\n",
        "### 4. Store Inputs in Object Variables\n",
        "\n",
        "```python\n",
        "self.text = text\n",
        "self.labels = labels\n",
        "self.tokenizer = tokenizer\n",
        "self.max_len = max_len\n",
        "```\n",
        "\n",
        "#### What this does:\n",
        "\n",
        "Stores the inputs so they can be used later by the dataset.\n",
        "\n",
        "### 5. **getitem** Method\n",
        "\n",
        "This method returns **one training example** at a time.\n",
        "\n",
        "```python\n",
        "def __getitem__(self, idx):\n",
        "```\n",
        "\n",
        "#### Purpose:\n",
        "\n",
        "Given an index `idx`, it returns:\n",
        "\n",
        "* Tokenized text\n",
        "* Attention mask\n",
        "* Label\n",
        "\n",
        "PyTorch uses this to create batches.\n",
        "\n",
        "### 6. Tokenize the Sentence\n",
        "\n",
        "```python\n",
        "enc = tokenizer(\n",
        "    self.text[idx], truncation=True, padding=\"max_length\",\n",
        "    max_length=self.max_len, return_tensors=\"pt\"\n",
        ")\n",
        "```\n",
        "\n",
        "#### What this does:\n",
        "\n",
        "It converts a single sentence into:\n",
        "\n",
        "* `input_ids`\n",
        "* `attention_mask`\n",
        "* (optional) `token_type_ids`\n",
        "\n",
        "##### Parameters:\n",
        "\n",
        "| Parameter                 | Meaning                            |\n",
        "| ------------------------- | ---------------------------------- |\n",
        "| `self.text[idx]`          | Get sentence at index `idx`        |\n",
        "| `truncation=True`         | Cuts long sentences beyond max_len |\n",
        "| `padding=\"max_length\"`    | Pads short ones to the same length |\n",
        "| `max_length=self.max_len` | Maximum token length               |\n",
        "| `return_tensors=\"pt\"`     | Returns PyTorch tensors            |\n",
        "\n",
        "##### Output example:\n",
        "\n",
        "```python\n",
        "{\n",
        " 'input_ids': tensor([...]),\n",
        " 'attention_mask': tensor([...])\n",
        "}\n",
        "```\n",
        "\n",
        "### 7. Remove Extra Batch Dimension\n",
        "\n",
        "```python\n",
        "enc = {k: v.squeeze(0) for k,v in enc.items()}\n",
        "```\n",
        "\n",
        "#### Why?\n",
        "\n",
        "Tokenizer returns shape:\n",
        "\n",
        "```\n",
        "(1, max_len)\n",
        "```\n",
        "\n",
        "But Trainer expects:\n",
        "\n",
        "```\n",
        "(max_len,)\n",
        "```\n",
        "\n",
        "So `.squeeze(0)` removes the first dimension.\n",
        "\n",
        "### 8. Add Label to Dictionary\n",
        "\n",
        "```python\n",
        "enc[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "```\n",
        "\n",
        "#### What this does:\n",
        "\n",
        "Adds the label so Trainer knows the correct class.\n",
        "\n",
        "Example:\n",
        "\n",
        "```\n",
        "enc[\"labels\"] = tensor(1)\n",
        "```\n",
        "\n",
        "This dictionary will be passed into the model.\n",
        "\n",
        "### 9. Return Single Training Example\n",
        "\n",
        "```python\n",
        "return enc\n",
        "```\n",
        "\n",
        "#### What it returns:\n",
        "\n",
        "A dictionary like:\n",
        "\n",
        "```python\n",
        "{\n",
        " 'input_ids': tensor([...]),\n",
        " 'attention_mask': tensor([...]),\n",
        " 'labels': tensor(1)\n",
        "}\n",
        "```\n",
        "\n",
        "This is exactly what **BERT** needs for training.\n",
        "\n",
        "### 10. len Method\n",
        "\n",
        "```python\n",
        "def __len__(self):\n",
        "    return len(self.text)\n",
        "```\n",
        "\n",
        "#### Purpose:\n",
        "\n",
        "Returns how many samples are in the dataset.\n",
        "\n",
        "If you have 100 sentences:\n",
        "\n",
        "```\n",
        "len(dataset) → 100\n",
        "```\n",
        "\n",
        "Trainer uses this to know how many batches to create."
      ],
      "metadata": {
        "id": "ui0WTWlYqwiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "class BERTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, text, labels, tokenizer, max_len=32):\n",
        "      # Since the dataset is small, using max_len=32 is sufficient and improves training speed.\n",
        "        self.text = text\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc = tokenizer(\n",
        "            self.text[idx], truncation=True, padding=\"max_length\",\n",
        "            max_length=self.max_len, return_tensors=\"pt\"\n",
        "        )\n",
        "        enc = {k: v.squeeze(0) for k,v in enc.items()}\n",
        "        enc[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return enc\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)"
      ],
      "metadata": {
        "id": "TnjD1VpKqQks"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Dataset"
      ],
      "metadata": {
        "id": "vdxX4tXjsLTD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. input_ids\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "'input_ids': tensor([101, 1045, 5223, 2023, 1012, 102, 0, 0, 0, ...])\n",
        "```\n",
        "\n",
        "#### What is `input_ids`?\n",
        "\n",
        "These numbers are **token IDs** — BERT vocabulary numbers.\n",
        "\n",
        "Example decoding:\n",
        "\n",
        "| Token   | ID   |\n",
        "| ------- | ---- |\n",
        "| `[CLS]` | 101  |\n",
        "| `I`     | 1045 |\n",
        "| `love`  | 5223 |\n",
        "| `this`  | 2023 |\n",
        "| `.`     | 1012 |\n",
        "| `[SEP]` | 102  |\n",
        "\n",
        "Everything after that becomes `0` because of padding.\n",
        "\n",
        "#### Why do we pad with zeros?\n",
        "\n",
        "Because BERT needs **fixed sequence length**, here `max_len=64`.\n",
        "If sentence is short, we pad with zeros.\n",
        "\n",
        "### 2. token_type_ids\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "'token_type_ids': tensor([0, 0, 0, 0, ..., 0])\n",
        "```\n",
        "\n",
        "#### What is this?\n",
        "\n",
        "Token type IDs tell BERT whether a token belongs to:\n",
        "\n",
        "* Sentence A → **0**\n",
        "* Sentence B → **1**\n",
        "\n",
        "Used for **next sentence prediction**.\n",
        "\n",
        "But in **classification**, we only have 1 sentence → so ALL are **0**.\n",
        "\n",
        "### 3. attention_mask\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "'attention_mask': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...])\n",
        "```\n",
        "\n",
        "#### What does attention mask do?\n",
        "\n",
        "It tells BERT **which tokens are real** and **which are padding**:\n",
        "\n",
        "| Mask value | Meaning                            |\n",
        "| ---------- | ---------------------------------- |\n",
        "| `1`        | Token must be attended (real word) |\n",
        "| `0`        | Ignore this token (padding)        |\n",
        "\n",
        "So here the first 6 tokens are real, rest 58 are padding zeros.\n",
        "\n",
        "### 4. labels\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "'labels': tensor(0)\n",
        "```\n",
        "\n",
        "#### This is the actual label for training.\n",
        "\n",
        "If it is a binary classification:\n",
        "\n",
        "* `0` = Negative\n",
        "* `1` = Positive\n",
        "\n",
        "In your example:\n",
        "\n",
        "```\n",
        "First sample → label = 0\n",
        "Second sample → label = 1\n",
        "```\n",
        "\n",
        "This is what the model tries to predict."
      ],
      "metadata": {
        "id": "4W3o-1u6tR3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = BERTDataset(train_df.text.tolist(), train_df.label.tolist(), tokenizer)\n",
        "val_dataset   = BERTDataset(val_df.text.tolist(), val_df.label.tolist(), tokenizer)\n",
        "print(train_dataset[0])\n",
        "print(val_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TObQgNysW-j",
        "outputId": "8040be6e-bd14-4825-8642-a32c4b4a5801"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([ 101, 1045, 5223, 2023, 1012,  102,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(0)}\n",
            "{'input_ids': tensor([ 101, 1045, 2293, 2023, 3042,  999,  102,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(1)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "Ss02lPoYsS0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. BertForSequenceClassification\n",
        "\n",
        "This is a **pretrained BERT model designed for classification tasks**, such as:\n",
        "\n",
        "* Sentiment analysis\n",
        "* Spam detection\n",
        "* Fake review detection\n",
        "* Binary or multi-class classification\n",
        "\n",
        "It adds a special **classification layer** (a linear layer) on top of BERT.\n",
        "\n",
        "So BERT outputs → go into a classifier to predict labels.\n",
        "\n",
        "###2. .from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "This loads the **pretrained BERT weights** from HuggingFace.\n",
        "\n",
        "#### \"bert-base-uncased\" means:\n",
        "\n",
        "* **base** = 12 layers, 110 million parameters\n",
        "* **uncased** = lowercase model (ignores capital letters)\n",
        "\n",
        "  * “Apple” → “apple”\n",
        "  * “HELLO” → “hello”\n",
        "\n",
        "It downloads:\n",
        "\n",
        "* Vocabulary\n",
        "* Model architecture\n",
        "* Pretrained weights from huge corpus (Wikipedia + Books)\n",
        "\n",
        "###3. num_labels=2\n",
        "\n",
        "This tells BERT how many classes your classification problem has.\n",
        "\n",
        "#### Since num_labels=2:\n",
        "\n",
        "* Label **0** → e.g., negative\n",
        "* Label **1** → e.g., positive\n",
        "\n",
        "This configures the final classification layer as:\n",
        "\n",
        "```\n",
        "Hidden size → 2 output logits\n",
        "```\n",
        "\n",
        "So model outputs:\n",
        "\n",
        "```\n",
        "[logit_for_class_0, logit_for_class_1]\n",
        "```\n",
        "\n",
        "The higher logit determines the predicted class."
      ],
      "metadata": {
        "id": "0c7kM3RavwSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "3299c9f2ce8445ca9e6073dab7c42df9",
            "5daa8bf798f143fe9be7a7651faf95ae",
            "b24b3432e9d34d3ca8c6b815ddb8b587",
            "f8c70bb1376c410db9b9eb6c30d0c392",
            "d94b14f04a19429d84ac730d6c23198b",
            "30840515b92545a9a48d7bb16e1a5a1d",
            "130531e18a4046b89e8626ef9feac433",
            "6a39553be7dd40859e7554f60a67b852",
            "5f1984d9ee4e42a792b6d624fe43e382",
            "d6db6f7c5c9742eb81ed9f8fd7f50cde",
            "cf762abb47ed4ad5a610aed51bf504db"
          ]
        },
        "id": "zHspddqQq0cH",
        "outputId": "987592af-ed36-4791-81eb-c9ea10f3f2c3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3299c9f2ce8445ca9e6073dab7c42df9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6RiH7xtu3rN",
        "outputId": "c1308bd1-2d58-40da-a13e-d649a5ab1ff9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=768, out_features=2, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Arguments"
      ],
      "metadata": {
        "id": "XzMEeDJDsURh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###output_dir=\"./bin_cls\"\n",
        "\n",
        "#### Meaning:\n",
        "\n",
        "This is the folder where:\n",
        "\n",
        "* Fine-tuned model\n",
        "* Checkpoints\n",
        "* Config files\n",
        "* Tokenizer files\n",
        "\n",
        "will be saved.\n",
        "\n",
        "Example directory created:\n",
        "\n",
        "```\n",
        "bin_cls/\n",
        "    ├── checkpoint-1/\n",
        "    ├── checkpoint-2/\n",
        "    ├── config.json\n",
        "    ├── pytorch_model.bin\n",
        "```\n",
        "\n",
        "You MUST specify this — HuggingFace Trainer requires it.\n",
        "\n",
        "###report_to=\"none\"\n",
        "#### Meaning:\n",
        "\n",
        "Disable ALL external logging integrations.\n",
        "\n",
        "This disables:\n",
        "\n",
        "* Weights & Biases (wandb)\n",
        "* MLflow\n",
        "* TensorBoard (except manual logs)\n",
        "* Comet\n",
        "\n",
        "Without this, Trainer tries to report logs to wandb if it's installed.\n",
        "\n",
        "So:\n",
        "\n",
        "```\n",
        "report_to=\"none\" = No visualization tools used\n",
        "```\n",
        "\n",
        "This keeps training output clean.\n",
        "\n",
        "###save_strategy=\"epoch\"\n",
        "\n",
        "#### Meaning:\n",
        "\n",
        "Save a checkpoint **at the end of every epoch**.\n",
        "\n",
        "If you train 2 epochs → it saves:\n",
        "\n",
        "```\n",
        "checkpoint-1/\n",
        "checkpoint-2/\n",
        "```\n",
        "\n",
        "Useful because you can:\n",
        "\n",
        "* Resume training\n",
        "* Compare performance of different checkpoints\n",
        "* Avoid losing progress if Colab disconnects\n",
        "\n",
        "###logging_dir=\"./logs\"\n",
        "\n",
        "#### Meaning:\n",
        "\n",
        "Where training logs will be stored.\n",
        "\n",
        "Logs include:\n",
        "\n",
        "* Loss\n",
        "* Evaluation metrics\n",
        "* Learning rate\n",
        "\n",
        "You can later view them using TensorBoard.\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "%tensorboard --logdir ./logs\n",
        "```\n",
        "\n",
        "###learning_rate=2e-5\n",
        "\n",
        "#### Meaning:\n",
        "\n",
        "This sets the speed at which model updates weights.\n",
        "\n",
        "`2e-5` = 0.00002\n",
        "\n",
        "This is the most recommended learning rate for BERT training.\n",
        "\n",
        "Why small?\n",
        "\n",
        "* BERT is pretrained\n",
        "* Large LR destroys pretrained knowledge\n",
        "* Small LR fine-tunes gently\n",
        "\n",
        "###num_train_epochs=2\n",
        "\n",
        "#### Meaning:\n",
        "\n",
        "Number of full passes through the training dataset.\n",
        "\n",
        "* 1 epoch → fast but low performance\n",
        "* **2–3 epochs** is typical for BERT\n",
        "* Too many epochs → overfitting\n",
        "\n",
        "So `2 epochs` is a safe, good starting point.\n",
        "\n",
        "###per_device_train_batch_size=4\n",
        "\n",
        "#### Meaning:\n",
        "\n",
        "Number of samples processed in one batch **per GPU/CPU**.\n",
        "\n",
        "* Batch size 4 fits small GPUs\n",
        "* Larger batch → faster training but needs more VRAM\n",
        "\n",
        "Typical BERT batch sizes:\n",
        "\n",
        "| GPU VRAM | Recommended batch |\n",
        "| -------- | ----------------- |\n",
        "| 8 GB     | 4                 |\n",
        "| 12 GB    | 8                 |\n",
        "| 16+ GB   | 16                |\n",
        "\n",
        "Batch size 4 is safe for most environments.\n"
      ],
      "metadata": {
        "id": "N6ppgtDh05C3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bin_cls\",\n",
        "    report_to=\"none\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=4, #2\n",
        "    per_device_train_batch_size=2 #4\n",
        ")\n"
      ],
      "metadata": {
        "id": "PBrbAXoasWGx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Increasing the number of training epochs from 2 to 4 allows the model to learn more from the data, while reducing the batch size from 4 to 2 increases training updates per epoch and can improve generalization, though it may also increase training time and overfitting risk."
      ],
      "metadata": {
        "id": "hu_qZKIdMK9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainer"
      ],
      "metadata": {
        "id": "dqBns0THsYre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "sTNxx8R2sZkE",
        "outputId": "6aa7e391-1c9b-46b3-8c30-3a4cd07f5b5c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [12/12 01:40, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=12, training_loss=0.5481272141138712, metrics={'train_runtime': 109.2446, 'train_samples_per_second': 0.183, 'train_steps_per_second': 0.11, 'total_flos': 328888819200.0, 'train_loss': 0.5481272141138712, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "1vozPE7zsaLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = trainer.predict(val_dataset)\n",
        "y_pred = pred.predictions.argmax(1)\n",
        "y_true = pred.label_ids\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "SUMzH7DVsbUw",
        "outputId": "0f59300a-cfca-438c-ef00-d46413cf42df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         1\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving FineTuned Model"
      ],
      "metadata": {
        "id": "teyZpE3F2zKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"./bin_cls\")\n",
        "tokenizer.save_pretrained(\"./bin_cls\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OizJDe5W23p3",
        "outputId": "fabe71d6-e17d-4dfa-af41-5ab0e79f500f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./bin_cls/tokenizer_config.json',\n",
              " './bin_cls/special_tokens_map.json',\n",
              " './bin_cls/vocab.txt',\n",
              " './bin_cls/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilizing the Finetune Model"
      ],
      "metadata": {
        "id": "uPxh0mbv2XwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"./bin_cls\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"./bin_cls\")"
      ],
      "metadata": {
        "id": "YbooYDeaz3FX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_with_confidence(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "    probs = torch.softmax(logits, dim=1)\n",
        "\n",
        "    pred_id = probs.argmax(dim=1).item()\n",
        "    class_name = label_names[pred_id]\n",
        "    confidence = probs[0][pred_id].item()\n",
        "\n",
        "    return class_name, confidence"
      ],
      "metadata": {
        "id": "iU-cnydw2dy0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = {0: \"Negative\", 1: \"Positive\"}"
      ],
      "metadata": {
        "id": "PT2d5CMf3LK9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I enjoy rainy days\"\n",
        "label, conf = predict_with_confidence(text)\n",
        "print(f\"Text: {text}\")\n",
        "print(f\"Prediction: {label}\")\n",
        "print(f\"Confidence: {conf*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIJyJukW5ZOQ",
        "outputId": "d77cc1ff-7bfa-4d63-9081-022a347a948f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: I enjoy rainy days\n",
            "Prediction: Negative\n",
            "Confidence: 56.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Binary Sentiment Dataset"
      ],
      "metadata": {
        "id": "LI2xy_P88_jL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"dineshpiyasamara/sentiment-analysis-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_d1LqjR8_AP",
        "outputId": "b445e0f4-2d04-414f-f2e8-72b81f7c36d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/dineshpiyasamara/sentiment-analysis-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 460k/460k [00:00<00:00, 38.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/dineshpiyasamara/sentiment-analysis-dataset/versions/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "files = os.listdir(path)\n",
        "for file in files:\n",
        "    if file.endswith(\".csv\"):\n",
        "        df = pd.read_csv(path + \"/\" + file)\n",
        "        print(\"Loaded:\", file)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtFhnwbn9E4U",
        "outputId": "a149b5d2-e4b6-495b-b17a-67700dd8d711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: sentiment_analysis.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "M0VjilLP9MTk",
        "outputId": "f74d8423-2949-46d6-ffa7-4d7f23dbd06e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id  label                                              tweet\n",
              "0        1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
              "1        2      0  Finally a transparant silicon case ^^ Thanks t...\n",
              "2        3      0  We love this! Would you go? #talk #makememorie...\n",
              "3        4      0  I'm wired I know I'm George I was made that wa...\n",
              "4        5      1  What amazing service! Apple won't even talk to...\n",
              "...    ...    ...                                                ...\n",
              "7915  7916      0  Live out loud #lol #liveoutloud #selfie #smile...\n",
              "7916  7917      0  We would like to wish you an amazing day! Make...\n",
              "7917  7918      0  Helping my lovely 90 year old neighbor with he...\n",
              "7918  7919      0  Finally got my #smart #pocket #wifi stay conne...\n",
              "7919  7920      0  Apple Barcelona!!! #Apple #Store #BCN #Barcelo...\n",
              "\n",
              "[7920 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28de8a52-be6e-41ef-b08b-38d2e3d70350\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>What amazing service! Apple won't even talk to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7915</th>\n",
              "      <td>7916</td>\n",
              "      <td>0</td>\n",
              "      <td>Live out loud #lol #liveoutloud #selfie #smile...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7916</th>\n",
              "      <td>7917</td>\n",
              "      <td>0</td>\n",
              "      <td>We would like to wish you an amazing day! Make...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7917</th>\n",
              "      <td>7918</td>\n",
              "      <td>0</td>\n",
              "      <td>Helping my lovely 90 year old neighbor with he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7918</th>\n",
              "      <td>7919</td>\n",
              "      <td>0</td>\n",
              "      <td>Finally got my #smart #pocket #wifi stay conne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7919</th>\n",
              "      <td>7920</td>\n",
              "      <td>0</td>\n",
              "      <td>Apple Barcelona!!! #Apple #Store #BCN #Barcelo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7920 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28de8a52-be6e-41ef-b08b-38d2e3d70350')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28de8a52-be6e-41ef-b08b-38d2e3d70350 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28de8a52-be6e-41ef-b08b-38d2e3d70350');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c9fd6f7f-3a16-4ff3-8662-5e41b86f7695\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9fd6f7f-3a16-4ff3-8662-5e41b86f7695')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c9fd6f7f-3a16-4ff3-8662-5e41b86f7695 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7033ed6d-9558-4bee-988e-1c1af97e3d20\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7033ed6d-9558-4bee-988e-1c1af97e3d20 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 7920,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2286,\n        \"min\": 1,\n        \"max\": 7920,\n        \"num_unique_values\": 7920,\n        \"samples\": [\n          4897,\n          7540,\n          1678\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7918,\n        \"samples\": [\n          \"My face as dad gave me cards worth \\u00a320, 000.00 #gay #shopping #boy #macbook #apple #blonde #pickofthe http://instagr.am/p/Uo5Ue7H7A8/\",\n          \"@skullcandy your product is brutal, 1 headphone always stops working. Get it together #Sony ftw\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['tweet', 'label']]"
      ],
      "metadata": {
        "id": "ckC6qGiE9x7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "print(train_df)\n",
        "print(val_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocCWBn8199Rt",
        "outputId": "d5e6f67c-a221-440d-e29f-ced1a16ea313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  tweet  label\n",
            "4252  Cool Car wash idea #TheIsland #BankHolidayMond...      0\n",
            "4428  Photo: 35th #Birthday to the #Sony #walkman @t...      0\n",
            "7374  iPads are the biggest pile of fucking $&@*# on...      1\n",
            "1410  Yearbook? Hmmmmm #instagram #instagood #togeth...      0\n",
            "7896  So pissed! Macbook crashes, Apple Company does...      1\n",
            "...                                                 ...    ...\n",
            "5226  #Shana #tova!!! #Jewish #newyear everyone, may...      0\n",
            "5390  I'm so sick of buying new cell phone chargers....      1\n",
            "860   it, Want it, Have it! Download the free #iPhon...      0\n",
            "7603  Photo: #nikosx #iphone #beach #holiday #bw #ip...      0\n",
            "7270  Just got an iPhone 4S :) hehe #iPhone #apple #...      1\n",
            "\n",
            "[6336 rows x 2 columns]\n",
            "                                                  tweet  label\n",
            "4896  Photo: cause we both dressed up today  #boyfr...      0\n",
            "7539  @skullcandy your product is brutal, 1 headphon...      1\n",
            "1677  Sunset Today in Zeeland ;-) Samsung Mobile S4 ...      0\n",
            "1964  God $&@*# it playstation share feature!! Cutti...      0\n",
            "3025  Awe he's da bestest :) #boyfriend him #iloveyo...      0\n",
            "...                                                 ...    ...\n",
            "1419  Who is 15 today? Meee #Birthday #to #me #cake ...      0\n",
            "3939  @arualcampbell as if you you do nothing but re...      0\n",
            "7834  using new #macbookpro for last 3 days & batter...      1\n",
            "5137  @robertwindon I can't fix junk apple power cor...      1\n",
            "4434  Using my zoooom.... #zoom #lens #iphone #dogwa...      0\n",
            "\n",
            "[1584 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = BERTDataset(train_df.tweet.tolist(), train_df.label.tolist(), tokenizer)\n",
        "val_dataset   = BERTDataset(val_df.tweet.tolist(), val_df.label.tolist(), tokenizer)\n",
        "print(train_dataset[0])\n",
        "print(val_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM6wmej_-WZF",
        "outputId": "f38a697a-9f19-40af-f54d-755b5bb9a6c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([  101,  4658,  2482,  9378,  2801,  1001,  1996,  2483,  3122,  1001,\n",
            "         2924, 14854,  8524, 24335, 29067,  2100, 10957,  1001, 10957, 11442,\n",
            "         4710,  1001, 25157,  4140,  1001, 27125, 26887,  1001,  2431, 22591,\n",
            "        13469,  1001,  5070, 11968,  3207,  2860,  1001,  4913,  5297,  1001,\n",
            "         2258, 18656,  1001, 19102,  1001, 18059,  1001, 28205,  2015,  1001,\n",
            "         2482,  1001, 13154,  1001,  1048,  2290,  1001, 18798, 16059,  1001,\n",
            "         4202, 26760, 10128,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}\n",
            "{'input_ids': tensor([  101,  6302,  1024,  3426,  2057,  2119,  5102,  2039,  2651,  1001,\n",
            "         6898,  1001,  5102,  6279,  1001, 10140,  1001, 18059,  1001,  2082,\n",
            "         1001, 16021, 15900, 17139,  1012,  1012,  1012,  8299,  1024,  1013,\n",
            "         1013,  1056, 14905, 20974,  1012,  2522,  1013,  1062,  2243,  1035,\n",
            "        28177, 24335,  3406,  4779,  2860,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(0)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "print(model.classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3JCwn22-X18",
        "outputId": "16637e10-d79e-4539-a2da-c6139966b881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=768, out_features=2, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bin_cls\",\n",
        "    report_to=\"none\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "stOQD129-tbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "2I-pxx---6a4",
        "outputId": "547b9741-f216-4216-fc88-be0181164a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='44' max='396' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 44/396 30:19 < 4:14:08, 0.02 it/s, Epoch 0.22/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = trainer.predict(val_dataset)\n",
        "y_pred = pred.predictions.argmax(1)\n",
        "y_true = pred.label_ids\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "bVOsgSk6-9nI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"./bin_cls\")\n",
        "tokenizer.save_pretrained(\"./bin_cls\")"
      ],
      "metadata": {
        "id": "wZG5MYHU_C4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"./bin_cls\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"./bin_cls\")"
      ],
      "metadata": {
        "id": "fe5ozy39_Dh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = \"Battery life is awful, I regret buying this.\"\n",
        "label, conf = predict_with_confidence(text)\n",
        "print(f\"Text: {tweet}\")\n",
        "print(f\"Prediction: {label}\")\n",
        "print(f\"Confidence: {conf*100:.2f}%\")"
      ],
      "metadata": {
        "id": "-TasqqDO_JoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 02: Multi-Class Classification"
      ],
      "metadata": {
        "id": "3dZtUe2TC8nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"text\": [\n",
        "        \"The phone is great\",       # positive\n",
        "        \"Battery is average\",       # neutral\n",
        "        \"Worst camera ever\",        # negative\n",
        "        \"Amazing sound quality\",    # positive\n",
        "        \"Not good, not bad\",        # neutral\n",
        "        \"Terrible performance\"      # negative\n",
        "    ],\n",
        "    \"label\": [2,1,0,2,1,0]           # 0=Neg, 1=Neutral, 2=Pos\n",
        "}\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "Hsj8QpjTDAg7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "print(train_df)\n",
        "print(val_df)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "class BERTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, text, labels, tokenizer, max_len=16):\n",
        "        self.text = text\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc = tokenizer(\n",
        "            self.text[idx], truncation=True, padding=\"max_length\",\n",
        "            max_length=self.max_len, return_tensors=\"pt\"\n",
        "        )\n",
        "        enc = {k: v.squeeze(0) for k,v in enc.items()}\n",
        "        enc[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return enc\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "train_dataset = BERTDataset(train_df.text.tolist(), train_df.label.tolist(), tokenizer)\n",
        "val_dataset   = BERTDataset(val_df.text.tolist(), val_df.label.tolist(), tokenizer)\n",
        "print(train_dataset[0])\n",
        "print(val_dataset[0])\n",
        "\n",
        "# Re-initialize the model with the correct number of labels (3 for 0, 1, 2)\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bin_cls\",\n",
        "    report_to=\"none\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=5, #2\n",
        "    per_device_train_batch_size=1\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "pred = trainer.predict(val_dataset)\n",
        "y_pred = pred.predictions.argmax(1)\n",
        "y_true = pred.label_ids\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred))\n",
        "trainer.save_model(\"./bin_cls\")\n",
        "tokenizer.save_pretrained(\"./bin_cls\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"./bin_cls\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"./bin_cls\")\n",
        "def predict_with_confidence(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "    probs = torch.softmax(logits, dim=1)\n",
        "\n",
        "    pred_id = probs.argmax(dim=1).item()\n",
        "    class_name = label_names[pred_id]\n",
        "    confidence = probs[0][pred_id].item()\n",
        "\n",
        "    return class_name, confidence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "id": "Xl8J1Z8JM3za",
        "outputId": "2dbb1974-c25e-4e5b-f844-70d606dcb253"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    text  label\n",
            "5   Terrible performance      0\n",
            "2      Worst camera ever      0\n",
            "4      Not good, not bad      1\n",
            "3  Amazing sound quality      2\n",
            "                 text  label\n",
            "0  The phone is great      2\n",
            "1  Battery is average      1\n",
            "{'input_ids': tensor([ 101, 6659, 2836,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(0)}\n",
            "{'input_ids': tensor([ 101, 1996, 3042, 2003, 2307,  102,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(2)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 02:55, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.33      0.33      0.33         2\n",
            "weighted avg       0.50      0.50      0.50         2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = {0: \"Negative\", 1: \"Positive\", 2:\"Neutral\",}\n",
        "text = \"They need to talk\"\n",
        "label, conf = predict_with_confidence(text)\n",
        "print(f\"Text: {text}\")\n",
        "print(f\"Prediction: {label}\")\n",
        "print(f\"Confidence: {conf*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnV9mMqmM3gA",
        "outputId": "96a69c52-6350-4770-8083-55931796a4c3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: They need to talk\n",
            "Prediction: Neutral\n",
            "Confidence: 37.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 03: Name Entity Relation"
      ],
      "metadata": {
        "id": "szO2YBwnDMnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"John lives in London\",\n",
        "    \"Sara works at Google\"\n",
        "]\n",
        "ner_tags = [\n",
        "    [\"B-PER\", \"O\", \"O\", \"B-LOC\"],\n",
        "    [\"B-PER\", \"O\", \"O\", \"B-ORG\"]\n",
        "]"
      ],
      "metadata": {
        "id": "NvLrSutfDSM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {\"O\":0, \"B-PER\":1, \"B-LOC\":2, \"B-ORG\":3}"
      ],
      "metadata": {
        "id": "p_BW8VePDUxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "LQsucnccDXQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = tokenizer(\n",
        "    sentences,\n",
        "    is_split_into_words=False,\n",
        "    return_offsets_mapping=True,\n",
        "    padding=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "encoded_labels = []\n",
        "for i, sentence in enumerate(sentences):\n",
        "    word_ids = encoded.word_ids(batch_index=i)\n",
        "    tag_ids = []\n",
        "    j = 0\n",
        "    for word_id in word_ids:\n",
        "        if word_id is None:\n",
        "            tag_ids.append(-100)\n",
        "        else:\n",
        "            tag_ids.append(labels[ner_tags[i][word_id]])\n",
        "    encoded_labels.append(tag_ids)\n",
        "\n",
        "encoded.pop(\"offset_mapping\")"
      ],
      "metadata": {
        "id": "LsZ7r1YnDdYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NERDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k,v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "KbtZK42EDeZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 04: Sentence Similarity"
      ],
      "metadata": {
        "id": "AVaQzsgIDk1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent1 = [\"The sky is blue\", \"Dogs are running\"]\n",
        "sent2 = [\"The sky is very blue\", \"A group of dogs run\"]\n",
        "scores = [4.5, 4.0]"
      ],
      "metadata": {
        "id": "PkdSRJmcDoSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "encodings = tokenizer(\n",
        "    sent1, sent2,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "labels = torch.tensor(scores)"
      ],
      "metadata": {
        "id": "Xxs3snzMDrTq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}